# HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models

[ğŸ™ GitHub Page](https://github.com/Zhaolu-K/HSSBench)  [ğŸ¤— HSSBench](https://huggingface.co/datasets/dozo/HSSBench)

## ğŸ’¡ Introduction
Current benchmarks for evaluating MLLMs primarily emphasize general knowledge and vertical step-by-step reasoning typical of STEM disciplines, while overlooking the distinct needs and potential of the Humanities and Social Sciences (HSS). Tasks in the HSS domain require more horizontal, interdisciplinary thinking and a deep integration of knowledge across related fields, which presents unique challenges for MLLMs, particularly in linking abstract concepts with corresponding visual representations. Addressing this gap, we present HSSBench, a dedicated benchmark designed to assess the capabilities of MLLMs on HSS tasks in multiple languages, including the six official languages of the United Nations. We also introduce a novel data generation pipeline tailored for HSS scenarios, in which multiple domain experts and automated agents collaborate to generate and iteratively refine each sample.

## ğŸ“– Dataset

### Data Format

## ğŸ“Š Model Performance
We test the  model performance under 2 scenarios: (1)Directly OR CoT answer, and (2) Multi-choice OR Open.

### One-Shot Performance
